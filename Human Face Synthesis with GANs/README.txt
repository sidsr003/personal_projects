This deep convolutional generative adversarial network uses a competitive generator-discriminator pair in what is effectively a two-player minimax game. The discriminator (D) aims to minimize the binary cross entropy loss in classifying an image as originating from the original data distribution whereas the generator (G) attempts to maximize that loss by improving its ability to counterfeit images to appear to originate from the original data distribution. This is typically formalized in terms of a value function V(G, D) that is minimized and maximized over the two MLPs. The model_saves folder contains the network weights and can be loaded. The image_saves folder contains a sample image array as it evolves through training iterations. The parametric_interpolation folder contains the result of interpolating the latent space coordinates and observing the resulting counterfeit image produced by the generator. The GAN is theoretically guaranteed to converge because the optimal G and D minimize the Jensen-Shannon divergence between the data distribution and counterfeit distribution. Of course, this is predicated on the fact that the network complexity is not a bottleneck (universal approximation theorem), nor the extent of training.

Paper referred to: https://arxiv.org/pdf/1406.2661 (Generative Adversarial Nets, Goodfellow et al.)